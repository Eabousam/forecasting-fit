{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5074a246-2238-42ea-b0cb-71a1020a3d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###score probalisitc forecast\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import log_loss, brier_score_loss\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9021e0-9787-4b8d-b516-e329e0841c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input data in format \n",
    "\n",
    "locations = [ \"United Kingdom\",\"Japan\"]\n",
    "dates = ['2022-01-24', '2022-02-04','2022-02-08','2022-02-18','2022-02-23',\n",
    "         '2022-02-28','2022-03-03','2022-03-08','2022-03-15',\n",
    "         '2022-03-21','2022-03-25','2022-04-07','2022-04-14','2022-04-27'\n",
    "         ,'2022-05-06','2022-05-17','2022-05-20','2022-05-28','2022-06-09'\n",
    "         ,'2022-06-14','2022-06-22']\n",
    "\n",
    "#Latest model run \"truth\"\n",
    "truth_set = pd.read_csv(\"https://raw.githubusercontent.com/blab/rt-from-frequency-dynamics/master/estimates/omicron-countries-split/omicron-countries-split_freq-combined-GARW.tsv\", sep=\"\\t\")\n",
    "final_truth = truth_set.rename(columns = {'median_freq':'truth_freq'}, inplace = False)\n",
    "final_truth = final_truth[final_truth['location']=='United Kingdom']\n",
    "final_truth = final_truth[['date','location','variant','truth_freq']]\n",
    "\n",
    "\n",
    "#full model output set dict\n",
    "\n",
    "\n",
    "final_sets = {}\n",
    "pred_dic = {}\n",
    "for date in dates:\n",
    "    filepath = f\"cast_estimates_full/United Kingdom/freq_full_{date}.csv\"\n",
    "    \n",
    "    #Check if file exists and continue if not\n",
    "    if not os.path.exists(filepath):\n",
    "        continue\n",
    "    #read models and add to dict\n",
    "    pred_dic[date] = pd.read_csv(f\"cast_estimates_full/United Kingdom/freq_full_{date}.csv\")\n",
    "\n",
    "    #loop through data and merge to final set\n",
    "final_sets = {k: pd.merge(final_truth,d) for k,d in pred_dic.items()} \n",
    "#print(final_sets.keys())\n",
    "\n",
    "print(final_sets)          \n",
    "                            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668223ba-5eba-4ca6-a54e-26797e6b03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_freq_data(final_set):\n",
    "    \n",
    "    \n",
    "    #return truth values as np.arrays\n",
    "    \n",
    "    truth_values = final_set['truth_freq'].to_numpy()\n",
    "    \n",
    "    #return nowcast and forecast values as np.arrays\n",
    "    \n",
    "    nowcast_values = final_set['median_freq_nowcast'].to_numpy()\n",
    "    \n",
    "    forecast_values = final_set['median_freq_forecast'].to_numpy()\n",
    "    \n",
    "    return truth_values, nowcast_values, forecast_values\n",
    "\n",
    "\n",
    "#prep arrays of data\n",
    "prepped_data = {k: prep_freq_data(v) for k,v in final_sets.items()}\n",
    "print(prepped_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62fcac5b-1747-4e85-b55d-a003bffe03aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class scores to get scores\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59481b0e-b5ad-404a-af83-df235dd294cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scores(ABC):\n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        pass\n",
    "class MAE(Scores):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def evaluate(self,truth, prediction):\n",
    "        abs_error = np.abs(truth - prediction)\n",
    "        return np.nanmean(abs_error)\n",
    "        \n",
    "class MSE(Scores):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def evaluate(self, truth, prediction):\n",
    "        squared_error = np.square(truth - prediction)\n",
    "        return np.nanmean(squared_error)\n",
    "        \n",
    "class LogLoss(Scores):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        #mlr log loss error\n",
    "    def evaluate(self, truth, prediction):\n",
    "        log_loss = sklearn.metrics.log_loss(self.truth, prediction, eps=1e-15, normalize=True, sample_weight=None, labels=None)\n",
    "        return log_loss\n",
    "\n",
    "\n",
    "    \n",
    "error_id_dict = {}    \n",
    "for k, v in prepped_data.items():\n",
    "    error_dict={}\n",
    "    #MAE\n",
    "    \n",
    "    error = MAE()  \n",
    "    error_dict['MAE'] = error.evaluate(v[0],v[1])\n",
    "    \n",
    "    #MSE\n",
    "    mse = MSE()\n",
    "    error_dict['MSE'] = mse.evaluate(v[0],v[1])\n",
    "    \n",
    "    error_id_dict[k] = error_dict\n",
    "    \n",
    "print(error_id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022db951-cc92-4ed9-9d3b-065815e3552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarize results\n",
    "\n",
    "out = []\n",
    "\n",
    "for k,v in error_id_dict.items():\n",
    "    #print(v)\n",
    "    v['MAE']\n",
    "    #v['MSE']\n",
    "    out.append(v['MAE'])\n",
    "    #out.append(v['MSE'])\n",
    "\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
