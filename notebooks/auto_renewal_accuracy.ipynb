{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1071417-a685-4e50-8d6a-349f84947511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "import evofr as ef\n",
    "from numpyro.infer.autoguide import AutoDelta, AutoMultivariateNormal\n",
    "from pathlib import Path\n",
    "import os\n",
    "from jax import vmap\n",
    "import jax.numpy as jnp\n",
    "from jax.nn import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4293fd4c-1aed-4255-8472-d7148b72e65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/eabousam/freq_dynamics/ncov-forecasting-fit/notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69434412-e7a5-4653-b355-092140960a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/eslamabousamra/rt_frq_dyn_datasets/ncov-forecasting-fit'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/Users/eabousam/freq_dynamics/ncov-forecasting-fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00a5b2c1-b678-4c94-9bfd-52ace164fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting sequences data from commit dates\n",
    "dates = ['2022-04-15','2022-04-22','2022-04-29','2022-05-06',\n",
    "         '2022-05-13','2022-05-20','2022-05-27','2022-06-03',\n",
    "         '2022-06-10','2022-06-17','2022-06-24','2022-06-30']\n",
    "\n",
    "#specifying location to run model on\n",
    "locations = [\"USA\", \"United Kingdom\", \"Brazil\",\"Australia\",\"South Africa\", \"Japan\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af407e4a-1756-40f7-9ee5-bad020b6efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model\n",
    "seed_L = 14\n",
    "forecast_L = 14\n",
    "ps = [0.95, 0.8, 0.5]\n",
    "# Get delays\n",
    "v_names = ['Delta', \n",
    "           'Omicron 21L', \n",
    "           'Omicron 21K', \n",
    "           'Omicron 22A', \n",
    "           'Omicron 22B', \n",
    "           'Omicron 22C', \n",
    "           'other']\n",
    "\n",
    "gen = ef.pad_delays(\n",
    "    [ef.discretise_gamma(mn=4.4, std=1.2), # Delta\n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 21L\n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 21K #3.1 std 1.2 \n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 22A\n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 22B\n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 22C\n",
    "     ef.discretise_gamma(mn=4.4, std=1.2)] # Other\n",
    "    )\n",
    "\n",
    "delays = ef.pad_delays([ef.discretise_lognorm(mn=3.1, std=1.0)])  \n",
    "\n",
    "basis_fn = ef.Spline(order = 4, k = 10)\n",
    "#dict for models\n",
    "model_type = dict()\n",
    "\n",
    "\n",
    "#Fixed Growth Advantage model for variants\n",
    "model_type['FGA'] = ef.RenewalModel(gen, delays, seed_L, forecast_L, k=10,\n",
    "                RLik = ef.FixedGA(0.1), #Likelihood on effective reproduction number (GARW depend on R and gen time)\n",
    "                CLik = ef.ZINegBinomCases(0.05), #Case Likelihood\n",
    "                SLik = ef.DirMultinomialSeq(100), #Sequence Likelihood\n",
    "                v_names = v_names,\n",
    "                basis_fn = basis_fn)\n",
    "\n",
    "#model_type['GARW'] = ef.RenewalModel(gen, delays, seed_L, forecast_L, k=10,\n",
    "#                RLik = ef.GARW(0.1,0.1), #Likelihood on effective reproduction number (GARW depend on R and gen time)\n",
    "#                CLik = ef.ZINegBinomCases(0.05), #Case Likelihood\n",
    "#                SLik = ef.DirMultinomialSeq(100), #Sequence Likelihood\n",
    "#                v_names = v_names,\n",
    "#                basis_fn = basis_fn)\n",
    "\n",
    "#Varying Growth Advantage Random Walk Model\n",
    "model_type['GARW'] = ef.RenewalModel(gen, delays, seed_L, forecast_L, k=10,\n",
    "                RLik = ef.GARW(0.1,0.01, prior_family='Normal'), #Likelihood on effective reproduction number (GARW depend on R and gen time)\n",
    "                CLik = ef.ZINegBinomCases(0.05), #Case Likelihood\n",
    "                SLik = ef.DirMultinomialSeq(100), #Sequence Likelihood\n",
    "                v_names = v_names,\n",
    "                basis_fn = basis_fn)\n",
    "\n",
    "#Multinomial Logistic regression model\n",
    "model_type['MLR'] = ef.MultinomialLogisticRegression(tau=4.2)\n",
    "\n",
    "\n",
    "#Piantham model\n",
    "model_type['Piantham'] = ef.models.PianthamModel(gen = ef.discretise_gamma(mn=3.1, std=1.2))\n",
    "\n",
    "\n",
    "\n",
    "# defining inference method\n",
    "svi_fullrank = ef.InferFullRank(iters = 50_000, lr = 4e-3, num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65188165-d416-4e1e-9498-1bad24acfe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export posterior frequencies forecast and no forecast\n",
    "def save_freq(samples, variant_data, ps, forecast_date, name, filepath):\n",
    "    #only need last 14 days\n",
    "    freq_now = pd.DataFrame(ef.get_freq(samples, variant_data, ps, name=name, forecast = False))\n",
    "    #Get the freq dates nowcast period\n",
    "    nowcast_dates = variant_data.dates[-14:]\n",
    "    freq_now = freq_now[freq_now['date'].isin(nowcast_dates)]\n",
    "    freq_fr = pd.DataFrame(ef.get_freq(samples, variant_data, ps, name=name, forecast = True))\n",
    "    freq_merged = pd.concat([freq_now, freq_fr])\n",
    "    #freq_now = freq_now.rename(columns = {'median_freq':'median_freq_nowcast','freq_upper_95':'freq_nowcast_upper_95'}, inplace = False)\n",
    "    \n",
    "    #rename intervals\n",
    "    freq_merged = freq_merged.rename(columns = {'median_freq':'median_freq_nowcast','freq_upper_95':'freq_nowcast_upper_95'}, inplace = False)\n",
    "\n",
    "    freq_merged.to_csv(f'{filepath}/freq_full_{forecast_date}.csv', index = False)\n",
    "    #freq_now.to_csv(f'{filepath}/freq_nowcast_{forecast_date}.csv', index = False)\n",
    "    #freq_fr.to_csv(f'{filepath}/freq_forecast_{forecast_date}.csv', index = False)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ce44710-45a0-43ee-bc33-6f8e2bfe8d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #export posterior frequencies forecast and no forecast\n",
    "def save_mlr_freq(samples, variant_data, ps, forecast_date, name, filepath):\n",
    "\n",
    "    freq_fr = pd.DataFrame(ef.get_freq(samples, variant_data, ps, name=name, forecast = True))\n",
    "\n",
    "    #rename intervals\n",
    "    freq_fr = freq_fr.rename(columns = {'median_freq':'median_freq_nowcast','freq_upper_95':'freq_nowcast_upper_95'}, inplace = False)\n",
    "\n",
    "    freq_fr.to_csv(f'{filepath}/freq_full_{forecast_date}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4d72cde-0f19-460e-a863-e0c6fd4ae5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58d1f10b-fb79-40ad-bfc6-16547bda01c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_frequencies(samples, mlr, forecast_L):\n",
    "    \"\"\"\n",
    "    Use posterior beta to forecast posterior frequenicies.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Making feature matrix for forecasting\n",
    "    last_T = samples[\"freq\"].shape[1]\n",
    "    \n",
    "    X = mlr.make_ols_feature(start=last_T, stop=last_T + forecast_L)\n",
    "    # Posterior beta\n",
    "    beta = jnp.array(samples[\"beta\"])\n",
    "    \n",
    "    # Matrix multiplication by sample\n",
    "    dot_by_sample = vmap(jnp.dot, in_axes=(None, 0), out_axes=0)\n",
    "    logits = dot_by_sample(X, beta) # Logit frequencies by variant\n",
    "    return softmax(logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bdf8852-19e2-4f86-81c2-ea64eebd75c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gr_adv(samples, variant_data, ps, name, date, site, filepath):\n",
    "\n",
    "    growth_adv = pd.DataFrame(ef.posterior.get_site_by_variant(samples, variant_data, ps, name=name, site=site, forecast=False))\n",
    "\n",
    "    \n",
    "    growth_adv.to_csv(f'{filepath}/full_growth_advantages_{date}.csv',index = False, header = True)\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21ebe1d8-bbd4-4ed3-aa5b-a102f0f58f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlr_gr_adv(samples, variant_data, ps, name,date, filepath):\n",
    "    \n",
    "\n",
    "    growth_adv = pd.DataFrame(ef.posterior.get_growth_advantage(samples, variant_data, ps, name=name, rel_to=\"other\"))\n",
    "    growth_adv.to_csv(f'{filepath}/full_growth_advantages_{date}.csv',index = False, header=True)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "151afdcc-22b4-4a1f-9ee0-e910bb6ec68e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'locations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kc/wf32p71s4kb1_phml7_l_w5r0000gp/T/ipykernel_25099/2032211410.py\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mmodel_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/kc/wf32p71s4kb1_phml7_l_w5r0000gp/T/ipykernel_25099/2032211410.py\u001b[0m in \u001b[0;36mmodel_run\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#function to input models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mlocation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;31m#Output file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'locations' is not defined"
     ]
    }
   ],
   "source": [
    "models = ['Piantham','GARW','MLR', 'FGA']\n",
    "#'GARW',,'MLR'\n",
    "\n",
    "#function to input models \n",
    "def model_run(model):\n",
    "    for location in locations:\n",
    "        for date in dates:\n",
    "            #Output file path\n",
    "            filepath = f\"./plot-est/cast_estimates_full_{model}/{location}\"    \n",
    "            if not os.path.exists(filepath):\n",
    "                os.makedirs(filepath)\n",
    "            #read sequences\n",
    "            raw_seq = pd.read_csv(f\"data/time_stamped/{date}/seq_counts_{date}.tsv\", sep=\"\\t\")\n",
    "            raw_cases = pd.read_csv(f\"data/time_stamped/{date}/case_counts_{date}.tsv\", sep=\"\\t\")\n",
    "            raw_cases = raw_cases[raw_cases.location == location]\n",
    "            raw_seq = raw_seq[raw_seq.location == location]\n",
    "            if len(raw_cases)==0:\n",
    "                continue\n",
    "\n",
    "            #defining variant data (freq and seq)\n",
    "            #if model in ('Piantham','MLR'):\n",
    "            if model == 'MLR':\n",
    "                variant_data = ef.VariantFrequencies(raw_seq)\n",
    "                posterior = svi_fullrank.fit(model_type[model], variant_data)\n",
    "                posterior.samples[\"freq_forecast\"] = forecast_frequencies(posterior.samples, model_type[model], 28)\n",
    "                save_mlr_freq(posterior.samples, variant_data, ps, date, location, filepath)\n",
    "                samples = posterior.samples\n",
    "                #get_mlr_gr_adv(samples, variant_data, ps, location, date, filepath)\n",
    "                \n",
    "            if model == 'Piantham':\n",
    "                variant_data = ef.VariantFrequencies(raw_seq)\n",
    "                posterior = svi_fullrank.fit(model_type[model], variant_data)\n",
    "                #samples = posterior.samples\n",
    "                save_mlr_freq(posterior.samples, variant_data, ps, date, location, filepath)\n",
    "                #samples = posterior.samples\n",
    "                #get_mlr_gr_adv(samples, variant_data, ps, location, date, filepath)\n",
    "            if model == 'FGA':\n",
    "                variant_data = ef.CaseFrequencyData(raw_cases=raw_cases, raw_seq=raw_seq)\n",
    "                posterior = svi_fullrank.fit(model_type[model], variant_data)\n",
    "                #saving posterior frequencies\n",
    "                samples = posterior.samples\n",
    "                save_freq(posterior.samples, variant_data, ps, date, location, filepath)\n",
    "                #saving growth advantages\n",
    "                #get_mlr_gr_adv(samples, variant_data, ps, location, date, filepath)      \n",
    "            else:\n",
    "                variant_data = ef.CaseFrequencyData(raw_cases=raw_cases, raw_seq=raw_seq)\n",
    "                posterior = svi_fullrank.fit(model_type[model], variant_data)\n",
    "                #saving posterior frequencies\n",
    "                samples = posterior.samples\n",
    "                save_freq(posterior.samples, variant_data, ps, date, location, filepath)\n",
    "                #saving growth advantages\n",
    "                #get_gr_adv(samples, variant_data, ps, location, date, \"ga\", filepath)\n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "            \n",
    "    return None\n",
    " \n",
    "for model in models:\n",
    "    model_run(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
