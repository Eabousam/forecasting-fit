{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1071417-a685-4e50-8d6a-349f84947511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import Day, BDay\n",
    "import evofr as ef\n",
    "import numpy as np\n",
    "from jax import vmap\n",
    "from jax.nn import softmax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3479a933-d6d3-4377-8383-99f38521cd8a",
   "metadata": {},
   "source": [
    "## I. Specification of analysis period (Observation dates) and geographical settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e31339-c252-4a51-9094-8dc243af654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"../config.yaml\", 'r') as config:\n",
    "    config = yaml.safe_load(config)\n",
    "    \n",
    "dates = config[\"main\"][\"estimation_dates\"]\n",
    "locations = config[\"main\"][\"locations\"]\n",
    "models = config[\"main\"][\"models\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9349364-df7a-411a-80de-ef385cb52738",
   "metadata": {},
   "source": [
    "## II. Assigning parameters and forecasting period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0adca5a-f587-40be-bc3a-a56cc6eefd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters and forecasting period\n",
    "seed_L = 14\n",
    "forecast_L = 14\n",
    "forecast_new = 30\n",
    "ps = [0.95, 0.8, 0.5]\n",
    "\n",
    "# Get delays\n",
    "v_names = ['Delta', \n",
    "           'Omicron 21L', \n",
    "           'Omicron 21K', \n",
    "           'Omicron 22A', \n",
    "           'Omicron 22B', \n",
    "           'Omicron 22C',\n",
    "           'Omicron 22D',\n",
    "           'Omicron 22E',\n",
    "           'Omicron 23A',\n",
    "           'other']\n",
    "\n",
    "gen = ef.pad_delays(\n",
    "    [ef.discretise_gamma(mn=4.4, std=1.2), # Delta\n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 21L\n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 21K #3.1 std 1.2 \n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 22A\n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 22B\n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 22C\n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 22D\n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 22E\n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 23A\n",
    "     ef.discretise_gamma(mn=4.4, std=1.2)] # Other\n",
    "    )\n",
    "\n",
    "delays = ef.pad_delays([ef.discretise_lognorm(mn=3.1, std=1.0)])  \n",
    "\n",
    "basis_fn = ef.Spline(order=4, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2896c6-2143-4ec9-9056-b22475ec489c",
   "metadata": {},
   "source": [
    "## III. FGA, GARW, MLR, and Piantham models definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb673b-6238-431d-8e1c-1b9a81e629b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining models\n",
    "model_type = dict()\n",
    "\n",
    "\n",
    "#Fixed Growth Advantage model for variants\n",
    "model_type['FGA'] = ef.RenewalModel(gen, delays, seed_L, forecast_new,\n",
    "                RLik = ef.FixedGA(0.1), #Likelihood on effective reproduction number (GARW depend on R and gen time)\n",
    "                CLik = ef.ZINegBinomCases(0.05), #Case Likelihood\n",
    "                SLik = ef.DirMultinomialSeq(100), #Sequence Likelihood\n",
    "                v_names = v_names,\n",
    "                basis_fn = basis_fn)\n",
    "\n",
    "#Varying Growth Advantage Random Walk Model\n",
    "model_type['GARW'] = ef.RenewalModel(gen, delays, seed_L, forecast_new,\n",
    "                RLik = ef.GARW(0.1,0.01, prior_family='Normal'), #Likelihood on effective reproduction number (GARW depend on R and gen time)\n",
    "                CLik = ef.ZINegBinomCases(0.05), #Case Likelihood\n",
    "                SLik = ef.DirMultinomialSeq(100), #Sequence Likelihood\n",
    "                v_names = v_names,\n",
    "                basis_fn = basis_fn)\n",
    "\n",
    "#Multinomial Logistic regression model\n",
    "model_type['MLR'] = ef.MultinomialLogisticRegression(tau=4.2)\n",
    "\n",
    "#Piantham model\n",
    "model_type['Piantham'] = ef.models.PianthamModel(gen = ef.discretise_gamma(mn=3.1, std=1.2), forecast_L = forecast_new+14)\n",
    "\n",
    "# defining inference method\n",
    "#svi = ef.InferMAP(iters = 50_000, lr = 4e-3)\n",
    "svi = ef.InferFullRank(iters = 50_000, lr = 4e-3, num_samples=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c91854a-6985-45e3-b308-899c7ea635b9",
   "metadata": {},
   "source": [
    "## IV. Naive Model specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c962816-2115-41c8-b0f7-a79833221692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_forecast(seq_count_date, pivot, period=60):\n",
    "    \n",
    "    # Defining forecast and nowcast dates from pivot date\n",
    "    forecast_dates = pd.to_datetime(pd.unique(pd.date_range(start = pivot, periods=period, freq ='D') + Day(1))).astype(str)\n",
    "    nowcast_dates = pd.to_datetime(pd.unique(pd.date_range(end = pivot, periods=period, freq ='D'))).astype(str)\n",
    "\n",
    "    # Defining prediction period for nowcasting and forecasting\n",
    "    pred_dates = nowcast_dates.union(forecast_dates)\n",
    "  \n",
    "    # Computing frequency of variants for each location\n",
    "    seq_count_date['total_seq'] = seq_count_date.groupby(['date', 'location'])['sequences'].transform('sum')\n",
    "    seq_count_date['freq'] = seq_count_date['sequences']/seq_count_date['total_seq']\n",
    "    \n",
    "    # Adding pred_dates to date column for each location and variant\n",
    "    sc_s = []\n",
    "    for d in pred_dates:\n",
    "        # Defining recent_dates (7) from pivot date for each date in pred_dates\n",
    "        recent_dates = pd.Series(pd.to_datetime(seq_count_date[seq_count_date.date < d].date).unique()).nlargest(n=7).astype(str)\n",
    "\n",
    "        # Computing the mean frequency for recent dates\n",
    "        seq_count_mean = seq_count_date[seq_count_date.date.isin(recent_dates)].groupby([\"variant\", \"location\"])[\"freq\"].mean().reset_index()\n",
    "    \n",
    "        sc_ = seq_count_mean.copy()\n",
    "        \n",
    "        # Adding dates column\n",
    "        sc_[\"date\"] = d\n",
    "        sc_s.append(sc_)\n",
    "\n",
    "    sc = pd.concat(sc_s).sort_values(by=[\"location\", \"variant\", \"date\"])\n",
    "    \n",
    "    # Adding nowcast and forecast columns\n",
    "    sc['median_freq_nowcast'] = sc['freq']\n",
    "    sc['median_freq_forecast'] = sc['freq']\n",
    "    \n",
    "    # Matching dates for nowcast and forecast\n",
    "    sc.loc[sc.date.isin(forecast_dates),'median_freq_nowcast'] = np.nan\n",
    "    sc.loc[sc.date.isin(nowcast_dates),'median_freq_forecast'] = np.nan\n",
    "    return sc.reset_index(drop=True)\n",
    "    \n",
    "for pivot in dates:\n",
    "    seq_count_date = pd.read_csv(f\"../data/time_stamped/{pivot}/seq_counts_{pivot}.tsv\", sep=\"\\t\")\n",
    "    naive_pred = naive_forecast(seq_count_date, pivot)\n",
    "    \n",
    "    # Create files for estimates for each country and pivot date\n",
    "    for location in locations:\n",
    "        filepath = f'../estimates/naive/{location}/'\n",
    "        if not os.path.exists(filepath):\n",
    "            os.makedirs(filepath)\n",
    "        naive_pred[naive_pred.location == location].to_csv(filepath + f\"freq_full_{pivot}.tsv\", sep=\"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d68629d-5640-4fdf-835b-d77ec1110706",
   "metadata": {},
   "source": [
    "## V. Helper functions to export variant frequencies and growth advantages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65188165-d416-4e1e-9498-1bad24acfe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export posterior frequencies forecast and no forecast\n",
    "def save_freq(samples, variant_data, ps, forecast_date, name, filepath):\n",
    "    # Get nowcast frequencies\n",
    "    freq_now = pd.DataFrame(ef.get_freq(samples, variant_data, ps, name=name, forecast = False))\n",
    "    nowcast_dates = variant_data.dates[-60:]    \n",
    "    freq_now = freq_now[freq_now['date'].isin(nowcast_dates)]\n",
    "    \n",
    "    # Get forecasted frequencies\n",
    "    freq_fr = pd.DataFrame(ef.get_freq(samples, variant_data, ps, name=name, forecast = True))\n",
    "    \n",
    "    # Merge and export file\n",
    "    freq_merged = pd.concat([freq_now, freq_fr])\n",
    "    freq_merged = freq_merged.rename(columns = {'median_freq':'median_freq_nowcast'}, inplace = False)\n",
    "    freq_merged.to_csv(f'{filepath}/freq_full_{forecast_date}.tsv', sep=\"\\t\", index = False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce44710-45a0-43ee-bc33-6f8e2bfe8d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export posterior frequencies forecast and nowcast\n",
    "def save_mlr_freq(samples, variant_data, ps, forecast_date, name, filepath):\n",
    "    \n",
    "    # Get nowcast frequencies\n",
    "    freq_now = pd.DataFrame(ef.get_freq(samples, variant_data, ps, name=name, forecast = False))\n",
    "    nowcast_dates = variant_data.dates[-60:]\n",
    "    freq_now = freq_now[freq_now['date'].isin(nowcast_dates)]\n",
    "    \n",
    "    # Get forecasted frequencies\n",
    "    freq_fr = pd.DataFrame(ef.get_freq(samples, variant_data, ps, name=name, forecast = True))\n",
    "    \n",
    "    # Merge and export file\n",
    "    freq_merged = pd.concat([freq_now, freq_fr])\n",
    "    freq_merged = freq_merged.rename(columns = {'median_freq':'median_freq_nowcast'}, inplace = False)\n",
    "    freq_merged.to_csv(f'{filepath}/freq_full_{forecast_date}.tsv', sep=\"\\t\", index = False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d1f10b-fb79-40ad-bfc6-16547bda01c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_frequencies(samples, mlr, forecast_L):\n",
    "    \"\"\"\n",
    "    Use posterior beta to forecast posterior frequenicies.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Making feature matrix for forecasting\n",
    "    last_T = samples[\"freq\"].shape[1]    \n",
    "    X = mlr.make_ols_feature(start=last_T, stop=last_T + forecast_L)\n",
    "    \n",
    "    # Matrix multiplication by sample\n",
    "    beta = jnp.array(samples[\"beta\"])\n",
    "    dot_by_sample = vmap(jnp.dot, in_axes=(None, 0), out_axes=0)\n",
    "    logits = dot_by_sample(X, beta) # Logit frequencies by variant\n",
    "    return softmax(logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdf8852-19e2-4f86-81c2-ea64eebd75c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_varying_growth_advantage(samples, variant_data, ps, name, date, site, filepath):\n",
    "    growth_adv = pd.DataFrame(ef.posterior.get_site_by_variant(samples, variant_data, ps, name=name, site=site, forecast=False))    \n",
    "    growth_adv.to_csv(f'{filepath}/full_growth_advantages_{date}.tsv', sep=\"\\t\", index = False, header = True)\n",
    "    return None\n",
    "\n",
    "def get_fixed_growth_advantage(samples, variant_data, ps, name,date, filepath):\n",
    "    growth_adv = pd.DataFrame(ef.posterior.get_growth_advantage(samples, variant_data, ps, name=name, rel_to=\"Omicron 21L\"))\n",
    "    growth_adv.to_csv(f'{filepath}/full_growth_advantages_{date}.tsv', sep=\"\\t\", index = False, header=True)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054628df-4ab3-4338-b241-ed85d7163eb6",
   "metadata": {},
   "source": [
    "## VI. Running models and exporting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec00b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, location, date, raw_seq, raw_cases):      \n",
    "    # Model fitting and exporting files\n",
    "    if model == 'MLR':\n",
    "        # Fit models and forecast\n",
    "        variant_data = ef.VariantFrequencies(raw_seq, pivot=\"Omicron 21L\")\n",
    "        posterior = svi.fit(model_type[model], variant_data)\n",
    "        posterior.samples[\"freq_forecast\"] = forecast_frequencies(posterior.samples, model_type[model], 74)\n",
    "\n",
    "        # Save frequencies and growth advantages\n",
    "        save_mlr_freq(posterior.samples, variant_data, ps, date, location, filepath)\n",
    "        get_fixed_growth_advantage(posterior.samples, variant_data, ps, location, date, filepath)\n",
    "                \n",
    "    if model == 'Piantham':\n",
    "        # Fit models and forecast\n",
    "        variant_data = ef.VariantFrequencies(raw_seq, pivot=\"Omicron 21L\")\n",
    "        posterior = svi.fit(model_type[model], variant_data)\n",
    "                \n",
    "        # Save frequencies and growth advantages\n",
    "        save_freq(posterior.samples, variant_data, ps, date, location, filepath)\n",
    "        get_fixed_growth_advantage(posterior.samples, variant_data, ps, location, date, filepath)\n",
    "    \n",
    "    if model == 'FGA':\n",
    "        # Fit models and forecast\n",
    "        variant_data = ef.CaseFrequencyData(raw_cases=raw_cases, raw_seq=raw_seq, pivot=\"Omicron 21L\")\n",
    "        posterior = svi.fit(model_type[model], variant_data)\n",
    "                \n",
    "        # Save frequencies and growth advantages\n",
    "        save_freq(posterior.samples, variant_data, ps, date, location, filepath)\n",
    "        get_fixed_growth_advantage(posterior.samples, variant_data, ps, location, date, filepath)  \n",
    "    \n",
    "    if model == 'GARW':\n",
    "        # Fit models and forecast\n",
    "        variant_data = ef.CaseFrequencyData(raw_cases=raw_cases, raw_seq=raw_seq, pivot=\"Omicron 21L\")\n",
    "        posterior = svi.fit(model_type[model], variant_data)\n",
    "                \n",
    "        # Save frequencies and growth advantages\n",
    "        save_freq(posterior.samples, variant_data, ps, date, location, filepath)\n",
    "        get_time_varying_growth_advantage(posterior.samples, variant_data, ps, location, date, \"ga\", filepath)\n",
    "    return None\n",
    "\n",
    "for date in dates:\n",
    "    for location in locations:            \n",
    "        # Read data\n",
    "        raw_seq = pd.read_csv(f\"../data/time_stamped/{date}/seq_counts_{date}.tsv\", sep=\"\\t\")\n",
    "        raw_cases = pd.read_csv(f\"../data/time_stamped/{date}/case_counts_{date}.tsv\", sep=\"\\t\")\n",
    "        \n",
    "        # Filter data\n",
    "        raw_cases = raw_cases[raw_cases.location == location]\n",
    "        raw_seq = raw_seq[raw_seq.location == location]\n",
    "\n",
    "        # Check if data present\n",
    "        if len(raw_cases)==0 or len(raw_seq) == 0:\n",
    "            continue\n",
    "            \n",
    "        for model in models:\n",
    "            # Create output file path\n",
    "            filepath = f\"../estimates/{model}/{location}\"    \n",
    "            if not os.path.exists(filepath):\n",
    "                os.makedirs(filepath)\n",
    "\n",
    "            run_model(model, location, date, raw_seq, raw_cases)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
