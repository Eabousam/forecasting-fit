{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1071417-a685-4e50-8d6a-349f84947511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "import evofr as ef\n",
    "from numpyro.infer.autoguide import AutoDelta, AutoMultivariateNormal\n",
    "from pathlib import Path\n",
    "import os\n",
    "from jax import vmap\n",
    "import jax.numpy as jnp\n",
    "from jax.nn import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pandas.tseries.offsets import Day, BDay\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4293fd4c-1aed-4255-8472-d7148b72e65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/eabousam/freq_dynamics/ncov-forecasting-fit'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "os.chdir('/Users/eabousam/freq_dynamics/ncov-forecasting-fit') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3479a933-d6d3-4377-8383-99f38521cd8a",
   "metadata": {},
   "source": [
    "# I. Specification of analysis Period (Observation dates) and geographical settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81e31339-c252-4a51-9094-8dc243af654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting sequences data from commit dates\n",
    "dates = ['2022-01-01','2022-02-01','2022-03-01','2022-04-01',\n",
    "         '2022-05-01','2022-06-01','2022-07-01','2022-08-01',\n",
    "         '2022-09-01','2022-10-01','2022-11-01','2022-12-01']\n",
    "\n",
    "#specifying location to run model on\n",
    "locations = [\"USA\", \"United Kingdom\", \"Brazil\",\"Australia\",\"South Africa\", \"Japan\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9349364-df7a-411a-80de-ef385cb52738",
   "metadata": {},
   "source": [
    "# II. Assigning Parameters and Forecasting Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0adca5a-f587-40be-bc3a-a56cc6eefd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters and forecasting period\n",
    "seed_L = 14\n",
    "forecast_L = 14\n",
    "forecast_new = 30\n",
    "ps = [0.95, 0.8, 0.5]\n",
    "# Get delays\n",
    "v_names = ['Delta', \n",
    "           'Omicron 21L', \n",
    "           'Omicron 21K', \n",
    "           'Omicron 22A', \n",
    "           'Omicron 22B', \n",
    "           'Omicron 22C',\n",
    "           'Omicron 22D',\n",
    "           'Omicron 22E',\n",
    "           'Omicron 23A',\n",
    "           'other']\n",
    "\n",
    "gen = ef.pad_delays(\n",
    "    [ef.discretise_gamma(mn=4.4, std=1.2), # Delta\n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 21L\n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 21K #3.1 std 1.2 \n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 22A\n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 22B\n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 22C\n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 22D\n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 22E\n",
    "     ef.discretise_gamma(mn=3.1, std=1.2), # Omicron 23A\n",
    "     ef.discretise_gamma(mn=4.4, std=1.2)] # Other\n",
    "    )\n",
    "\n",
    "delays = ef.pad_delays([ef.discretise_lognorm(mn=3.1, std=1.0)])  \n",
    "\n",
    "basis_fn = ef.Spline(order = 4, k = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2896c6-2143-4ec9-9056-b22475ec489c",
   "metadata": {},
   "source": [
    "# III. FGA, GARW, MLR, and Piantham Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71fb673b-6238-431d-8e1c-1b9a81e629b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining models\n",
    "#dict for models\n",
    "model_type = dict()\n",
    "\n",
    "\n",
    "#Fixed Growth Advantage model for variants\n",
    "model_type['FGA'] = ef.RenewalModel(gen, delays, seed_L, forecast_new,\n",
    "                RLik = ef.FixedGA(0.1), #Likelihood on effective reproduction number (GARW depend on R and gen time)\n",
    "                CLik = ef.ZINegBinomCases(0.05), #Case Likelihood\n",
    "                SLik = ef.DirMultinomialSeq(100), #Sequence Likelihood\n",
    "                v_names = v_names,\n",
    "                basis_fn = basis_fn)\n",
    "\n",
    "#Varying Growth Advantage Random Walk Model\n",
    "model_type['GARW'] = ef.RenewalModel(gen, delays, seed_L, forecast_new,\n",
    "                RLik = ef.GARW(0.1,0.01, prior_family='Normal'), #Likelihood on effective reproduction number (GARW depend on R and gen time)\n",
    "                CLik = ef.ZINegBinomCases(0.05), #Case Likelihood\n",
    "                SLik = ef.DirMultinomialSeq(100), #Sequence Likelihood\n",
    "                v_names = v_names,\n",
    "                basis_fn = basis_fn)\n",
    "\n",
    "#Multinomial Logistic regression model\n",
    "model_type['MLR'] = ef.MultinomialLogisticRegression(tau=4.2)\n",
    "\n",
    "#Piantham model\n",
    "model_type['Piantham'] = ef.models.PianthamModel(gen = ef.discretise_gamma(mn=3.1, std=1.2), forecast_L = forecast_new+14)\n",
    "\n",
    "# defining inference method\n",
    "svi = ef.InferMAP(iters = 50_000, lr = 4e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c91854a-6985-45e3-b308-899c7ea635b9",
   "metadata": {},
   "source": [
    "# IV. Naive Model specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c962816-2115-41c8-b0f7-a79833221692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_forecast(seq_count_date, pivot, period=60):\n",
    "    \n",
    "    #defining forecast and nowcast dates from pivot date\n",
    "    forecast_dates = pd.to_datetime(pd.unique(pd.date_range(start = pivot, periods=period, freq ='D') + Day(1))).astype(str)\n",
    "    #print(forecast_dates)\n",
    "    nowcast_dates = pd.to_datetime(pd.unique(pd.date_range(end = pivot, periods=period, freq ='D'))).astype(str)\n",
    "    #print(forecast_dates)\n",
    "    #defining prediction period for nowcasting and forecasting\n",
    "    \n",
    "\n",
    "    #pred_dates = pd.concat((nowcast_dates, forecast_dates))\n",
    "    pred_dates = nowcast_dates.union(forecast_dates)\n",
    "    #print(pred_dates)\n",
    "  \n",
    "    #computing the frequency of variants for each location\n",
    "    seq_count_date['total_seq'] = seq_count_date.groupby(['date', 'location'])['sequences'].transform('sum')\n",
    "    seq_count_date['freq'] = seq_count_date['sequences']/seq_count_date['total_seq']\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    #Adding pred_dates to date column for each location and variant\n",
    "    sc_s = []\n",
    "    for d in pred_dates:\n",
    "        #defining recent_dates (7) from pivot date for each date in pred_dates\n",
    "        #recent_dates = pd.to_datetime(pd.unique(pd.date_range(end = d, periods=7, freq ='D') - Day(7))).astype(str) #that have available seq data\n",
    "        recent_dates = pd.Series(pd.to_datetime(seq_count_date[seq_count_date.date < d].date).unique()).nlargest(n=7).astype(str)\n",
    "        #print(d,recent_dates)\n",
    "        #print(d, recent_dates_n)\n",
    "        #Computing the mean frequency for recent dates\n",
    "        seq_count_mean = seq_count_date[seq_count_date.date.isin(recent_dates)].groupby([\"variant\", \"location\"])[\"freq\"].mean().reset_index()\n",
    "    \n",
    "        sc_ = seq_count_mean.copy()\n",
    "        #adding dates column\n",
    "        sc_[\"date\"] = d\n",
    "        sc_s.append(sc_)\n",
    "\n",
    "    sc = pd.concat(sc_s).sort_values(by=[\"location\", \"variant\", \"date\"])\n",
    "    #adding nowcast and forecast columns\n",
    "    sc['median_freq_nowcast'] = sc['freq']\n",
    "    sc['median_freq_forecast'] = sc['freq']\n",
    "    #matching dates for nowcast and forecast\n",
    "    sc.loc[sc.date.isin(forecast_dates),'median_freq_nowcast'] = np.nan\n",
    "    sc.loc[sc.date.isin(nowcast_dates),'median_freq_forecast'] = np.nan\n",
    "\n",
    "    return sc.reset_index(drop=True)\n",
    "\n",
    "\n",
    "for pivot in dates:\n",
    "    seq_count_date = pd.read_csv(f\"data/time_stamped/{pivot}/seq_counts_{pivot}.tsv\", sep=\"\\t\")\n",
    "    naive_pred = naive_forecast(seq_count_date, pivot)\n",
    "    print(naive_pred)\n",
    "    #create files for estimates for each country and pivot date\n",
    "    for location in locations:\n",
    "        filepath = f'plot-est2/cast_estimates_full_dummy/{location}/'\n",
    "        if not os.path.exists(filepath):\n",
    "            os.makedirs(filepath)\n",
    "        naive_pred[naive_pred.location == location].to_csv(filepath+f\"freq_full_{pivot}.csv\", index = False)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d68629d-5640-4fdf-835b-d77ec1110706",
   "metadata": {},
   "source": [
    "# V. Helper functions to export variant frequencies and growth advantages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65188165-d416-4e1e-9498-1bad24acfe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export posterior frequencies forecast and no forecast\n",
    "def save_freq(samples, variant_data, ps, forecast_date, name, filepath):\n",
    "    #only need last 14 days\n",
    "    freq_now = pd.DataFrame(ef.get_freq(samples, variant_data, ps, name=name, forecast = False))\n",
    "    #Get the freq dates nowcast period\n",
    "    #nowcast_dates = variant_data.dates[-14:]\n",
    "    nowcast_dates = variant_data.dates[-60:]\n",
    "    \n",
    "    freq_now = freq_now[freq_now['date'].isin(nowcast_dates)]\n",
    "    freq_fr = pd.DataFrame(ef.get_freq(samples, variant_data, ps, name=name, forecast = True))\n",
    "    freq_merged = pd.concat([freq_now, freq_fr])\n",
    "    #freq_now = freq_now.rename(columns = {'median_freq':'median_freq_nowcast','freq_upper_95':'freq_nowcast_upper_95'}, inplace = False)\n",
    "    \n",
    "    #rename intervals\n",
    "    freq_merged = freq_merged.rename(columns = {'median_freq':'median_freq_nowcast','freq_upper_95':'freq_nowcast_upper_95'}, inplace = False)\n",
    "\n",
    "    freq_merged.to_csv(f'{filepath}/freq_full_{forecast_date}.csv', index = False)\n",
    "    #freq_now.to_csv(f'{filepath}/freq_nowcast_{forecast_date}.csv', index = False)\n",
    "    #freq_fr.to_csv(f'{filepath}/freq_forecast_{forecast_date}.csv', index = False)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ce44710-45a0-43ee-bc33-6f8e2bfe8d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export posterior frequencies forecast and nowcast\n",
    "def save_mlr_freq(samples, variant_data, ps, forecast_date, name, filepath):\n",
    "\n",
    "    \n",
    "    freq_now = pd.DataFrame(ef.get_freq(samples, variant_data, ps, name=name, forecast = False))\n",
    "    #Get the freq dates nowcast period\n",
    "    nowcast_dates = variant_data.dates[-60:]\n",
    "    \n",
    "    freq_now = freq_now[freq_now['date'].isin(nowcast_dates)]\n",
    "    \n",
    "    freq_fr = pd.DataFrame(ef.get_freq(samples, variant_data, ps, name=name, forecast = True))\n",
    "    freq_merged = pd.concat([freq_now, freq_fr])\n",
    "    #rename intervals\n",
    "    freq_merged = freq_merged.rename(columns = {'median_freq':'median_freq_nowcast','freq_upper_95':'freq_nowcast_upper_95'}, inplace = False)\n",
    "\n",
    "    freq_merged.to_csv(f'{filepath}/freq_full_{forecast_date}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58d1f10b-fb79-40ad-bfc6-16547bda01c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_frequencies(samples, mlr, forecast_L):\n",
    "    \"\"\"\n",
    "    Use posterior beta to forecast posterior frequenicies.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Making feature matrix for forecasting\n",
    "    last_T = samples[\"freq\"].shape[1]\n",
    "    \n",
    "    X = mlr.make_ols_feature(start=last_T, stop=last_T + forecast_L)\n",
    "    # Posterior beta\n",
    "    beta = jnp.array(samples[\"beta\"])\n",
    "    \n",
    "    # Matrix multiplication by sample\n",
    "    dot_by_sample = vmap(jnp.dot, in_axes=(None, 0), out_axes=0)\n",
    "    logits = dot_by_sample(X, beta) # Logit frequencies by variant\n",
    "    return softmax(logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bdf8852-19e2-4f86-81c2-ea64eebd75c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Growth Advantage\n",
    "\n",
    "def get_gr_adv(samples, variant_data, ps, name, date, site, filepath):\n",
    "\n",
    "    growth_adv = pd.DataFrame(ef.posterior.get_site_by_variant(samples, variant_data, ps, name=name, site=site, forecast=False))\n",
    "\n",
    "    #get growth advantage relative to BA.1 Omicron 21K\n",
    "    \n",
    "    \n",
    "    growth_adv.to_csv(f'{filepath}/full_growth_advantages_{date}.csv',index = False, header = True)\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de756a1c-4622-4505-bbca-27bb55a47ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlr_gr_adv(samples, variant_data, ps, name,date, filepath):\n",
    "    \n",
    "\n",
    "    growth_adv = pd.DataFrame(ef.posterior.get_growth_advantage(samples, variant_data, ps, name=name, rel_to=\"Omicron 21L\"))\n",
    "    growth_adv.to_csv(f'{filepath}/full_growth_advantages_{date}.csv',index = False, header=True)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054628df-4ab3-4338-b241-ed85d7163eb6",
   "metadata": {},
   "source": [
    "# VI. Running models and exporting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b717e1c8-e376-4c92-b584-927f87ff508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['GARW','MLR', 'Piantham', 'FGA']\n",
    "#'Piantham','GARW',, 'FGA'\n",
    "\n",
    "#function to input models \n",
    "def model_run(model):\n",
    "    for location in locations:\n",
    "        for date in dates:\n",
    "            #Output file path\n",
    "            filepath = f\"./plot-est2/cast_estimates_full_{model}/{location}\"    \n",
    "            if not os.path.exists(filepath):\n",
    "                os.makedirs(filepath)\n",
    "            #read sequences\n",
    "            raw_seq = pd.read_csv(f\"data/time_stamped/{date}/seq_counts_{date}.tsv\", sep=\"\\t\")\n",
    "            raw_cases = pd.read_csv(f\"data/time_stamped/{date}/case_counts_{date}.tsv\", sep=\"\\t\")\n",
    "            raw_cases = raw_cases[raw_cases.location == location]\n",
    "            raw_seq = raw_seq[raw_seq.location == location]\n",
    "            if len(raw_cases)==0:\n",
    "                continue\n",
    "\n",
    "            #defining variant data (freq and seq)\n",
    "            if model == 'MLR':\n",
    "                variant_data = ef.VariantFrequencies(raw_seq, pivot=\"Omicron 21L\")\n",
    "                posterior = svi.fit(model_type[model], variant_data)\n",
    "                posterior.samples[\"freq_forecast\"] = forecast_frequencies(posterior.samples, model_type[model], 74)\n",
    "                samples = posterior.samples\n",
    "                save_mlr_freq(posterior.samples, variant_data, ps, date, location, filepath)\n",
    "                samples = posterior.samples\n",
    "                get_mlr_gr_adv(samples, variant_data, ps, location, date, filepath)\n",
    "                \n",
    "            if model == 'Piantham':\n",
    "                variant_data = ef.VariantFrequencies(raw_seq, pivot=\"Omicron 21L\")\n",
    "                posterior = svi.fit(model_type[model], variant_data)\n",
    "                samples = posterior.samples\n",
    "                save_freq(posterior.samples, variant_data, ps, date, location, filepath)\n",
    "                get_mlr_gr_adv(samples, variant_data, ps, location, date, filepath)\n",
    "            if model == 'FGA':\n",
    "                variant_data = ef.CaseFrequencyData(raw_cases=raw_cases, raw_seq=raw_seq, pivot=\"Omicron 21L\")\n",
    "                posterior = svi.fit(model_type[model], variant_data)\n",
    "                #saving posterior frequencies\n",
    "                samples = posterior.samples\n",
    "                save_freq(posterior.samples, variant_data, ps, date, location, filepath)\n",
    "                #saving growth advantages\n",
    "                get_mlr_gr_adv(samples, variant_data, ps, location, date, filepath)      \n",
    "            if model == 'GARW':\n",
    "                variant_data = ef.CaseFrequencyData(raw_cases=raw_cases, raw_seq=raw_seq, pivot=\"Omicron 21L\")\n",
    "                posterior = svi.fit(model_type[model], variant_data)\n",
    "                #saving posterior frequencies\n",
    "                samples = posterior.samples\n",
    "                save_freq(posterior.samples, variant_data, ps, date, location, filepath)\n",
    "                #saving growth advantages\n",
    "                get_gr_adv(samples, variant_data, ps, location, date, \"ga\", filepath)\n",
    "\n",
    "    return None\n",
    "\n",
    "for model in models:\n",
    "    model_run(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9328b8-d116-442e-a7c6-6ab56ca06dc2",
   "metadata": {},
   "source": [
    "Misc Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb54e41f-81ee-4747-a831-3399f4d44d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eabousam/opt/anaconda3/envs/forecasting-fit/lib/python3.9/site-packages/evofr/data/data_helpers.py:89: UserWarning: Omicron 21L not present in variant names. Using provided order.\n",
      "  warnings.warn(\n",
      "/Users/eabousam/opt/anaconda3/envs/forecasting-fit/lib/python3.9/site-packages/evofr/data/data_helpers.py:89: UserWarning: Omicron 21L not present in variant names. Using provided order.\n",
      "  warnings.warn(\n",
      "/Users/eabousam/opt/anaconda3/envs/forecasting-fit/lib/python3.9/site-packages/evofr/data/data_helpers.py:89: UserWarning: Omicron 21L not present in variant names. Using provided order.\n",
      "  warnings.warn(\n",
      "/Users/eabousam/opt/anaconda3/envs/forecasting-fit/lib/python3.9/site-packages/evofr/data/data_helpers.py:89: UserWarning: Omicron 21L not present in variant names. Using provided order.\n",
      "  warnings.warn(\n",
      "/Users/eabousam/opt/anaconda3/envs/forecasting-fit/lib/python3.9/site-packages/evofr/data/data_helpers.py:89: UserWarning: Omicron 21L not present in variant names. Using provided order.\n",
      "  warnings.warn(\n",
      "/Users/eabousam/opt/anaconda3/envs/forecasting-fit/lib/python3.9/site-packages/evofr/data/data_helpers.py:89: UserWarning: Omicron 21L not present in variant names. Using provided order.\n",
      "  warnings.warn(\n",
      "/Users/eabousam/opt/anaconda3/envs/forecasting-fit/lib/python3.9/site-packages/evofr/data/data_helpers.py:89: UserWarning: Omicron 21L not present in variant names. Using provided order.\n",
      "  warnings.warn(\n",
      "/Users/eabousam/opt/anaconda3/envs/forecasting-fit/lib/python3.9/site-packages/evofr/data/data_helpers.py:89: UserWarning: Omicron 21L not present in variant names. Using provided order.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "forecast_dates = pd.to_datetime(pd.unique(pd.date_range(start = date, periods=60, freq ='D') + Day(1))).astype(str)\n",
    "#print(forecast_dates)\n",
    "for date in dates:\n",
    "    nowcast_dates = pd.to_datetime(pd.unique(pd.date_range(end = date, periods=60, freq ='D'))).astype(str)\n",
    "    #print(nowcast_dates)\n",
    "\n",
    "recent_dates = pd.to_datetime(pd.unique(pd.date_range(end = date, periods=7, freq ='D') - Day(14))).astype(str)\n",
    "#print(recent_dates)\n",
    "#defining prediction period for nowcasting and forecasting\n",
    "pred_dates = pd.to_datetime(pd.unique(pd.date_range(start = date, periods=120, freq ='D') - Day(60))).astype(str)\n",
    "#print(pred_dates)\n",
    "for d in pred_dates:\n",
    "    #defining recent_dates (7) from pivot date for each date in pred_dates\n",
    "    for i in range(60):\n",
    "        recent_dates = pd.to_datetime(pd.unique(pd.date_range(end = date, periods=7, freq ='D') - Day(i))).astype(str)\n",
    "        #print(recent_dates)\n",
    "    #Computing the mean frequency for recent dates\n",
    "    seq_count_mean = seq_count_date[seq_count_date.date.isin(recent_dates)].groupby([\"variant\", \"location\"])[\"freq\"].mean().reset_index()\n",
    "\n",
    "test = pd.to_datetime(pd.unique(pd.date_range(start = date, periods= 60, freq ='D') - Day(14))).astype(str)\n",
    "print(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
